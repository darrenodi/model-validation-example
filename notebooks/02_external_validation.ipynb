{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model validation with external data\n",
    "In this notebook I will try to get the performance of the model on an external dataset I have obtained from a public repository, like ChEMBL, PubChem, Therapeutics Data Commons or MoleculeNet.\n",
    "\n",
    "I need to find a dataset for which experimental data exactly as the one used to train my model of interest is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this codeblock I will import the necessary packages and specify the paths to relevant folders\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Specify the paths to relevant folders and files\n",
    "model_predictions_file = '../data/output.csv'\n",
    "external_dataset_file = '../data/themolecules.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this codeblock I will load the external dataset as a pandas dataframe\n",
    "# model_predictions_df = pd.read_csv(model_predictions_file)\n",
    "external_dataset_df = pd.read_csv(external_dataset_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this codeblock I will process the external dataset so that I have a dataframe with three columns: standard smiles / InchiKey / experimental_value\n",
    "processed_external_dataset_df = process_external_dataset(external_dataset_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this codeblock I will make sure there are no repeated molecules between the train set used in the model and the external dataset I curated\n",
    "# Repeated molecules must be eliminated to avoid bias\n",
    "repeated_molecules = set(model_predictions_df['standard_smiles']).intersection(processed_external_dataset_df['standard_smiles'])\n",
    "\n",
    "if repeated_molecules:\n",
    "    print(f\"Warning: {len(repeated_molecules)} molecules are present in both the model training set and the external dataset. Removing them...\")\n",
    "    processed_external_dataset_df = processed_external_dataset_df[~processed_external_dataset_df['standard_smiles'].isin(repeated_molecules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this codeblock I will load the predictions I obtained with the EMH model and check several ML performance metrics\n",
    "\n",
    "# Load the model predictions from the DataFrame\n",
    "model_scores = model_predictions_df['score']\n",
    "\n",
    "# Load the experimental values from the processed external dataset DataFrame\n",
    "experimental_values = processed_external_dataset_df['experimental_value']\n",
    "\n",
    "# Calculate and print the performance metrics\n",
    "mse = mean_squared_error(experimental_values, model_scores)\n",
    "r2 = r2_score(experimental_values, model_scores)\n",
    "mae = mean_absolute_error(experimental_values, model_scores)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2) Score: {r2}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
